\documentclass[12pt]{article}

% ============================================================
% Packages
% ============================================================
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{float}
\usepackage{setspace}
\usepackage{xcolor}
\usepackage{array}
\usepackage{multirow}

\singlespacing  % Changed from \onehalfspacing to save space

\hypersetup{
  colorlinks=true,
  linkcolor=blue!60!black,
  citecolor=blue!60!black,
  urlcolor=blue!60!black
}

\graphicspath{{./}}

% ============================================================
% Title
% ============================================================
\title{\textbf{Do Financial Transfer Entropy Networks Recover\\
Meaningful Structure? A Matched-DGP Audit\\
of Node-Level Estimation Reliability}\\[0.3em]
\large Working Paper}

\author{Haotian Yang\thanks{Bocconi University. Email: \texttt{sorayoung.42@outlook.com}. Replication code: \url{https://github.com/sora42y/te-network-research-final}}}
\date{\today}

\begin{document}
\maketitle
\thispagestyle{empty}

% ============================================================
% Abstract
% ============================================================
\begin{abstract}
\noindent Financial network papers claim to identify systemically important nodes
using transfer entropy (TE), typically with $T/N < 5$. We ask: can these
methods recover network structure reliably?

At $T/N < 5$, OLS-based TE recovers under 17\% of true edges; hub detection
is close to random. LASSO achieves higher precision but produces near-empty
networks (density $<1\%$) on S\&P 500 data. Aggregate trends partially
survive: crisis-period density spikes appear in all Monte Carlo trials,
though magnitudes are attenuated. Node-level topology does not.

We run a power analysis: embed a known 10\% annualized network premium in
simulated data. The oracle $t$-statistic (true network) is 5.74; estimated
$t$-statistics at $T/N=5$ average 0.74. Even with 30\%+ annualized premia,
signals barely emerge. Estimation noise alone destroys realistic
network-return channels.

The $T/N$ barrier binds. Node-level claims in most existing work are
unreliable; aggregate trends may be defensible.

\medskip\noindent\textbf{Keywords:} Transfer entropy, Granger causality,
financial networks, estimation reliability, hub detection, LASSO-VAR,
$T/N$ barrier.

\medskip\noindent\textbf{JEL Classification:} G12, G14, C55, C58.
\end{abstract}

\newpage
\tableofcontents
\newpage

% ============================================================
% 1. Introduction
% ============================================================
\section{Introduction}

Directed network methods---Transfer Entropy (TE) and Granger causality (GC)---have been
applied to financial returns to draw node-level conclusions about systemic importance,
information leadership, and contagion. The foundational paper in
this tradition, \citet{billio2012}, tests pairwise bivariate GC among $N = 100$
financial institutions using $T = 36$ monthly observations ($T/N = 0.36$),
identifies banks as dominant ``hub'' shock transmitters, and proposes network
density as a systemic risk indicator. Their framework has been widely adopted:
\citet{demirer2018} extend it to $N = 96$ global banks with LASSO-regularized
VARs at $T/N = 1.56$; \citet{hue2019} rank 90 banks' systemic importance at
$T/N = 2.78$; and a parallel literature applies TE to equity and cryptocurrency
networks at comparable or lower $T/N$ ratios \citep{qiu2020, garciaMedina2020,
nascimento2022, bostanci2020}.

A common feature of these papers is that they make strong claims about network
topology --- which nodes are hubs, how centrality rankings shift during crises,
whether network statistics provide early-warning signals --- without validating
whether the network structure is \emph{recoverable} from data generated at
their actual $T/N$ ratios with known ground truth. \citet{billio2012} simulate
the false positive rate of the individual pairwise GC test but do not examine
whether assembling 9,900 such tests into a network yields correct hub identities.
\citet{demirer2018} justify their LASSO penalty by appeal to the regularization
literature but report no Monte Carlo validation of the resulting connectedness
rankings. The remaining papers report no simulation experiments at all.
Table~\ref{tab:literature} summarises these estimation regimes.

\begin{table}[htbp]
  \centering
  \caption{Estimation Regimes and Matched-DGP Validation Gap}
  \label{tab:literature}
  \small
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{llrrrp{3.5cm}p{3.5cm}p{3.5cm}p{2.0cm}}
    \toprule
    & Paper & $N$ & $T$ & $T/N$
      & Node-level claim
      & Aggregate-level claim
      & Our audit implication
      & DGP validated? \\
    \midrule
    1 & Billio et al.\ (2012), \textit{JFE}
      & 100 & 36 mo & 0.36
      & Banks identified as dominant hub shock transmitters
      & Network density as systemic risk indicator; sector-level connectedness
      & Hub identities unreliable (OLS precision 11\% at $T/N=0.36$); density trend defensible
      & No \\[4pt]
    2 & Qiu \& Yang (2020), \textit{Physica A}
      &  38 & 10--60\,d & 0.26--1.6
      & Individual stock hub identification; crisis early-warning stocks
      & Overall TE level during crises
      & Hub IDs unreliable; aggregate TE trend may be valid
      & No \\[4pt]
    3 & Demirer et al.\ (2018), \textit{JAE}
      &  96 & 150\,d & 1.56
      & Bank-specific centrality rankings; connectedness leaders
      & System-wide connectedness index (aggregate FEVD)
      & Centrality rankings unreliable; system-wide index less affected
      & No \\[4pt]
    4 & Nascimento et al.\ (2022), \textit{Fractals}
      &  67 & 130\,d & 1.94
      & BTC$\to$ETH directional leadership; specific crypto as information source
      & Pre/post-COVID aggregate TE change
      & Directional leadership claim unreliable; aggregate change directionally valid
      & No \\[4pt]
    5 & Hué et al.\ (2019), \textit{JEDC}
      &  90 & 250\,d & 2.78
      & G-SIB importance ranking (specific bank order)
      & Aggregate systemic importance score
      & Bank ranking order unreliable; aggregate score trends defensible
      & No (test-level only) \\[4pt]
    6 & García-Medina \& Hernández C.\ (2020), \textit{Entropy}
      & 146 & 504\,h & 3.45
      & Degree distribution shape; specific crisis-indicator nodes
      & Network density change during turbulence
      & Specific node roles unreliable; density increase during turbulence may reflect factor loading
      & No \\[4pt]
    7 & Bostanci \& Yilmaz (2020), \textit{JBF}
      &  38 & 150\,d & 3.95
      & Specific EM countries as shock generators; directional transmitter identity
      & Cross-country aggregate connectedness
      & Transmitter identities unreliable; aggregate connectedness directionally valid
      & No \\
    \bottomrule
  \end{tabular}}
  \medskip\\
  \small\textit{Note:} Node-level claims (hub identity, centrality ranking, directional leadership)
  require reliable edge-level estimation; our simulation shows this fails at all $T/N < 5$
  under realistic financial DGPs. Aggregate-level claims (mean TE, network density, system-wide
  connectedness indices) aggregate over many edges; our simulation shows
  OLS-TE detects crisis-period connectivity increases in 100\% of trials,
  though level magnitudes are severely attenuated (Section~\ref{sec:aggregate_recovery}).
\end{table}

This paper fills that gap. We provide the first systematic simulation study \emph{in the
financial network context} of TE/GC network recovery quality ---
not individual test properties --- as a function of the $T/N$ ratio.
The statistical breakdown of OLS at $T < N$ and LASSO precision--recall
trade-offs are well-established \citep{buhlmann2011,basu2015}; our
contribution is translating these results into concrete benchmarks
($T/N \approx 8$--$10$) for the specific parameter regimes of
financial network estimation. We then apply the resulting diagnostic framework to a
concrete downstream task: using Net Information Outflow (NIO) from TE networks
to predict cross-sectional equity returns.

\subsection{Overview and Contribution}

We run a matched-$(N,T)$ simulation audit of TE/GC network estimation across
$T/N$ ratios from 0.6 to 16.7, using three DGPs: Gaussian (baseline),
GARCH(1,1), and GARCH+Factor (realistic). At $T/N < 5$—the regime of all
seven papers in Table~\ref{tab:literature}—OLS precision is 7--17\% (83--93\%
false positives). LASSO achieves higher precision but near-zero recall,
collapsing to density $<1\%$ on S\&P 500 data. Hub detection performs close
to random.

We also embed a known 10\% annualized network premium in simulated data and
check if estimation recovers it. Oracle $t=5.74$ (significant); estimated
$t \approx 0.7$ at $T/N=5$ (noise). Even with 30\% premia, signals barely
emerge at $T/N=10$. This power test shows estimation noise alone destroys
plausible network-return channels.

Three contributions. First, we bridge the high-dimensional VAR literature
\citep{adamek2023, hecq2023} and the applied network literature by quantifying
\emph{network-level} recovery failure—hub detection, edge sets—at the exact
$(N,T)$ pairs used in published work. Second, we establish the $T/N$ barrier:
reliable edge-level estimation requires $T/N \approx 8$--10, far above
$T/N < 5$ used in most studies. Third, the power test sets a lower bound on
required $T/N$ for detectability, independent of whether network-return
mechanisms exist in real markets.

% ============================================================
% 2. Related Literature
% ============================================================
\section{Related Literature}

\paragraph{Financial network estimation.}
\citet{billio2012} establish the pairwise GC network as a systemic risk
measure. \citet{dieboldYilmaz2014} develop a connectedness framework based
on forecast error variance decompositions. \citet{demirer2018} extend this
to high dimensions with LASSO. \citet{hue2019} show that pairwise GC
produces persistent spurious causalities and propose a leave-one-out
correction; their Monte Carlo, however, evaluates the individual test
statistic, not network topology recovery.

\paragraph{Transfer entropy in finance.}
\citet{schreiber2000} introduces TE; \citet{barnett2009} establishes the
Gaussian equivalence to Granger causality. \citet{sandoval2014},
\citet{qiu2020}, \citet{garciaMedina2020}, and \citet{nascimento2022} apply
TE to financial networks at $T/N < 5$ without matched-$(N,T)$ simulation validation of
network-level claims. \citet{hecq2023} develop post-double-selection LASSO
for high-dimensional Granger causality but do not assess topological recovery.

\paragraph{Estimation quality in high-dimensional VARs.}
The high-dimensional statistics literature establishes that OLS breaks down
when $T/N < 1$ \citep{buhlmann2011}. \citet{basu2015} derive convergence
rates for LASSO-VAR. \citet{nicholson2020} implement structured penalization
for large VARs in the BigVAR package, widely used in applied work.
\citet{hautsch2015} address dimensionality in systemic risk
network estimation; \citet{barigozzi2019} propose the NETS
framework for factor-adjusted large VAR network estimation,
directly related to our factor-neutral preprocessing.
\citet{brownlees2021} provide inference theory for large-dimensional
GC networks. \citet{peel2017} show that hub recovery in noisy
graphs is unreliable even at moderate density---a finding this
paper instantiates in the financial network context.
Our contribution is to translate these general results
into a financial-network-specific simulation that quantifies hub recovery
accuracy at the exact $T/N$ ratios used in published papers --- an exercise
not previously conducted in the financial network literature.

% ============================================================
% 3. Methodology
% ============================================================
\section{Methodology}
\label{sec:method}

\subsection{Linear Transfer Entropy and Gaussian Equivalence}

Let $\varepsilon_{i,t}$ denote the factor-neutral return of stock $i$ at
time $t$ (construction in Section~\ref{sec:factorneutral}). Under a
first-order linear-Gaussian VAR \citep{barnett2009}:
\begin{equation}
  \mathrm{TE}(j \to i)
    = \frac{1}{2} \ln \frac{\sigma^2_{\mathrm{res}}}{\sigma^2_{\mathrm{full}}}
  \label{eq:te}
\end{equation}
where the restricted model regresses $\varepsilon_{i,t}$ on its own lag and
the full model adds $\varepsilon_{j,t-1}$. This equals pairwise Granger
causality under Gaussianity \citep{barnett2009}.

\subsection{Factor-Neutral Returns}
\label{sec:factorneutral}

Our baseline specification uses factor-neutral returns throughout. Before
computing TE, we project each stock's daily returns onto the Fama-French five
factors plus momentum within each rolling window and use the residuals as input:
\begin{equation}
  r_{i,t} = \alpha_i + \boldsymbol{\delta}_i^\top \mathbf{F}_t + \varepsilon_{i,t}
\end{equation}
and use $\hat{\varepsilon}_{i,t}$ as the input to all TE estimation. By the
Frisch-Waugh-Lovell theorem, this is equivalent to including $\mathbf{F}_t$
as additional controls in the VAR equations. The motivation is that pairwise
TE between stocks sharing common factor exposure captures factor-driven
co-movement, not genuine firm-specific information flow. Factor-neutral
preprocessing strips this contamination at the signal construction stage.
Results using raw (non-residualised) returns are reported as a robustness
check in Section~\ref{sec:factorcontam}.

\subsection{Network Construction and NIO}

We use rolling windows of $T$ trading days with 5-day roll steps. Net
Information Outflow is:
\begin{equation}
  \mathrm{NIO}_i = \frac{1}{N-1}\sum_{j \neq i}
    \bigl[\mathrm{TE}(i \to j) - \mathrm{TE}(j \to i)\bigr]
  \label{eq:nio}
\end{equation}

\subsection{OLS Pairwise Estimation}

The pairwise TE on factor-neutral residuals reduces via FWL to:
\begin{equation}
  \widehat{\mathrm{TE}}_{\mathrm{OLS}}(j \to i)
    = -\frac{1}{2}\ln\!\bigl(1 - \rho^2_{ij}\bigr)
\end{equation}
where $\rho_{ij} = \mathrm{corr}(\hat{\varepsilon}_i,\,
\hat{\varepsilon}_{j,t-1})$. This is the approach used by \citet{billio2012},
\citet{sandoval2014}, \citet{qiu2020}, and \citet{nascimento2022}. Its core
limitation: pairwise estimation cannot control for confounders, so a common
driver $A \to B$ and $A \to C$ generates spurious detection of $B \to C$.

\subsection{LASSO-Regularized Estimation}

Following \citet{hecq2023}, for each target stock $i$ we estimate:
\begin{equation}
  \hat{\varepsilon}_{i,t} = \alpha_i + \beta_i \hat{\varepsilon}_{i,t-1}
    + \sum_{j \neq i} \gamma_{ij} \hat{\varepsilon}_{j,t-1} + u_{i,t}
\end{equation}
by LASSO with $\lambda$ selected via BIC (\texttt{LassoLarsIC}). Edge
$j \to i$ is detected iff $\hat{\gamma}_{ij} \neq 0$. The TE magnitude is
the marginal leave-$j$-out contribution:
\begin{equation}
  \widehat{\mathrm{TE}}_{\mathrm{LASSO}}(j \to i)
    = \frac{1}{2}\ln\frac{\hat{\sigma}^2_{-j}}{\hat{\sigma}^2_{\mathrm{full}}}
  \label{eq:lasso_te}
\end{equation}
ensuring each edge reflects its own marginal contribution, not the total
model improvement.

\subsection{Cross-Sectional Testing}

We form quintile portfolios sorted on NIO (equal-weighted, 5-day forward
factor-adjusted returns) and a binary split: connected ($\mathrm{NIO} \neq 0$)
vs.\ isolated ($\mathrm{NIO} = 0$) stocks. We tested KNN-based nonparametric TE
($k=3$); precision was near-random at all $T/N$, consistent with the well-known
dimensionality curse of kernel entropy estimators (Appendix~\ref{app:nonparametric}).

% ============================================================
% 4. Simulation: Matched-DGP Validation
% ============================================================
\section{Simulation: Matched-DGP Validation}
\label{sec:simulation}

\subsection{Data Generating Process}

Our DGP is designed to match the empirical environment of the papers in
Table~\ref{tab:literature}:
\begin{equation}
  \mathbf{r}_t = \boldsymbol{\Lambda} \mathbf{f}_t
               + A\, \mathbf{r}_{t-1}
               + \boldsymbol{\sigma}_t \circ \boldsymbol{\eta}_t
  \label{eq:dgp}
\end{equation}
\begin{itemize}
  \item $\mathbf{f}_t \sim \mathcal{N}(0, I_3)$: three common factors with
        loadings $\Lambda_{ik} \sim \mathcal{U}(0, 0.5)$, imposing realistic
        cross-sectional correlation.
  \item $A$: $N \times N$ sparse VAR(1) matrix, true edge density 5\%,
        nonzero entries $\sim \mathcal{U}([-0.15,-0.05] \cup [0.05,0.15])$,
        rescaled to spectral radius 0.9.
        These parameters are illustrative; density sensitivity
        (2\%--20\%) and other robustness checks are reported in
        the appendix.
  \item $\sigma_{i,t}^2 = \omega_i + \alpha_i u_{i,t-1}^2 + \beta_i
        \sigma_{i,t-1}^2$: GARCH(1,1) with $\alpha_i \sim \mathcal{U}(0.05,
        0.10)$ and $\beta_i \sim \mathcal{U}(0.85, 0.90)$.
  \item $\boldsymbol{\eta}_t \sim t_5(0, I)$: Student-$t$ errors with 5
        degrees of freedom.
\end{itemize}
Factor-neutral returns (residuals from projecting $\mathbf{r}_t$ onto
$\mathbf{f}_t$) are used as input to TE estimation, as in our empirical
analysis. The DGP thus tests the end-to-end pipeline.

\subsection{Results}

Table~\ref{tab:main_results} reports network recovery metrics across three DGPs
and $(N, T)$ combinations spanning the range of published financial network
studies. Figure~\ref{fig:sim} plots the results for the \texttt{garch\_factor}
DGP, the most realistic specification.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{figure3_simulation.png}
  \caption{Network recovery under the \texttt{garch\_factor} DGP
           (common factors + GARCH(1,1) + $t_5$ errors).
           At $T/N < 5$ --- the regime of all seven papers in
           Table~\ref{tab:literature} --- OLS-TE precision is below 19\%,
           meaning over 80\% of detected edges are false positives.
           LASSO-TE precision is higher but recall is near zero.
           Results are strictly worse than under the Gaussian baseline.}
  \label{fig:sim}
\end{figure}

\begin{table}[htbp]
  \centering
  \caption{Network Recovery Quality: GARCH+Factor DGP (100 Monte Carlo trials per cell)}
  \label{tab:main_results}
  \small
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{rrrcccccc}
    \toprule
    & & & \multicolumn{3}{c}{OLS-TE} & \multicolumn{3}{c}{LASSO-TE} \\
    \cmidrule(lr){4-6}\cmidrule(lr){7-9}
    $T/N$ & $N$ & $T$ & Precision & F1 & Hub Rec. & Precision & F1 & Hub Rec. \\
    \midrule
    0.6 & 20 & 12 & 0.070$_{\pm0.010}$ & 0.084$_{\pm0.012}$ & 0.268$_{\pm0.035}$ & 0.065$_{\pm0.014}$ & 0.051$_{\pm0.011}$ & 0.268$_{\pm0.037}$ \\
    2.5 & 20 & 50 & 0.121$_{\pm0.013}$ & 0.137$_{\pm0.015}$ & 0.276$_{\pm0.036}$ & 0.199$_{\pm0.037}$ & 0.097$_{\pm0.019}$ & 0.338$_{\pm0.039}$ \\
    10.0 & 20 & 200 & 0.189$_{\pm0.011}$ & 0.258$_{\pm0.013}$ & 0.356$_{\pm0.036}$ & 0.458$_{\pm0.032}$ & 0.308$_{\pm0.021}$ & 0.384$_{\pm0.035}$ \\
    0.6 & 50 & 30 & 0.085$_{\pm0.004}$ & 0.096$_{\pm0.004}$ & 0.120$_{\pm0.026}$ & 0.139$_{\pm0.020}$ & 0.029$_{\pm0.004}$ & 0.124$_{\pm0.026}$ \\
    2.5 & 50 & 125 & 0.166$_{\pm0.005}$ & 0.218$_{\pm0.006}$ & 0.190$_{\pm0.035}$ & 0.568$_{\pm0.022}$ & 0.170$_{\pm0.010}$ & 0.152$_{\pm0.033}$ \\
    10.0 & 50 & 500 & 0.132$_{\pm0.004}$ & 0.216$_{\pm0.005}$ & 0.170$_{\pm0.031}$ & 0.794$_{\pm0.016}$ & 0.527$_{\pm0.011}$ & 0.332$_{\pm0.034}$ \\
    0.6 & 100 & 60 & 0.116$_{\pm0.003}$ & 0.140$_{\pm0.003}$ & 0.100$_{\pm0.026}$ & 0.375$_{\pm0.021}$ & 0.036$_{\pm0.003}$ & 0.070$_{\pm0.022}$ \\
    2.5 & 100 & 250 & 0.142$_{\pm0.003}$ & 0.219$_{\pm0.004}$ & 0.084$_{\pm0.023}$ & 0.926$_{\pm0.006}$ & 0.283$_{\pm0.008}$ & 0.122$_{\pm0.029}$ \\
    10.0 & 100 & 1000 & 0.075$_{\pm0.002}$ & 0.136$_{\pm0.003}$ & 0.070$_{\pm0.022}$ & 0.585$_{\pm0.029}$ & 0.575$_{\pm0.012}$ & 0.120$_{\pm0.033}$ \\
    \bottomrule
  \end{tabular}}
  \medskip\\
  \small\textit{Note:} Subscripts show 95\% CI half-widths (100 trials).
  Hub recovery = fraction of true top-5 out-degree nodes recovered.
  Random baseline: 10\% at $N\geq50$.
\end{table}

Three findings stand out. First, at $T/N < 5$ --- the regime of all seven
papers in Table~\ref{tab:literature} --- OLS-TE precision is 11--19\% across
all DGPs, meaning 81--89\% of detected edges are false positives. The
\citet{billio2012} regime of $T/N = 0.36$ (our $T/N = 0.6$ being the closest
cell) yields OLS precision of 10--15\% and F1 below 0.16 in every
specification. The specific banks identified as dominant hubs in that paper may be substantially affected by estimation noise
rather than reflecting structural features of the true information network.

Second, LASSO-TE achieves higher precision but near-zero recall at low $T/N$,
collapsing toward empty networks. The approach of \citet{demirer2018} ($T/N
= 1.56$) produces a network in which the few detected edges may be genuine,
but the vast majority of true edges are missed. Centrality rankings derived
from near-empty networks are not informative about the underlying information
structure.

Third, and most importantly for robustness, the Gaussian DGP is the
\emph{most favourable} environment for both estimators: under Gaussian
innovations, OLS-TE precision and F1 improve substantially as $T/N$ rises
above 5. Under GARCH and GARCH+Factor --- the realistic financial DGPs ---
this improvement largely disappears. OLS-TE precision remains stuck at
11--19\% even at $T/N = 16.7$ under GARCH+Factor. The implication is sharp:
\emph{network recovery failures are not merely a consequence of short samples;
they persist under realistic financial dynamics at sample sizes well above
those used in published work.}

% ============================================================


\subsection{Density Sensitivity Analysis}
\label{sec:density}

Table~\ref{tab:density} reports OLS-TE precision across four true network
densities at key $T/N$ ratios under the GARCH+Factor DGP.

\begin{table}[htbp]
  \centering
  \caption{OLS-TE Precision by True Network Density (GARCH+Factor DGP)}
  \label{tab:density}
  \small
  \begin{tabular}{rccccc}
    \toprule
    $T/N$ & density=2\% & density=5\% & density=10\% & density=20\% \\
    \midrule
    0.6  & 0.056 & 0.120 & 0.201 & 0.348 \\
    2.4  & 0.072 & 0.168 & 0.277 & 0.387 \\
    5.0  & 0.057 & 0.100 & 0.163 & 0.234 \\
    10.0 & 0.075 & 0.141 & 0.184 & 0.286 \\
    \bottomrule
  \end{tabular}
  \medskip\\
  \small\textit{Note:} Even at density=20\% (the most favourable setting),
  precision remains below 35\% at all $T/N$ ratios accessible with daily
  financial data. The T/N barrier holds across all density assumptions.
\end{table}


\subsection{Generated Regressor Effect: Oracle vs.\ Estimated Factor-Neutral}
\label{sec:oracle}

A concern with two-step estimation is that PCA-estimated factor loadings
introduce noise in the first step, biasing TE estimates in the second.
Table~\ref{tab:oracle} compares three specifications: raw returns (no factor
removal), oracle factor-neutral (true loadings), and estimated factor-neutral
(PCA with $K=3$ factors).

\begin{table}[htbp]
  \centering
  \caption{Oracle vs.\ Estimated Factor-Neutral: LASSO-TE Precision}
  \label{tab:oracle}
  \small
  \begin{tabular}{lccc}
    \toprule
    Method & $T/N=4$ & $T/N=5$ \\
    \midrule
    Raw (no factor removal) & 0.285 & 0.540 \\
    Oracle factor-neutral   & 0.271 & 0.835 \\
    Estimated (PCA)         & 0.446 & 0.812 \\
    \bottomrule
  \end{tabular}
  \medskip\\
  \small\textit{Note:} Oracle uses true factor loadings; Estimated(PCA) uses
  $K=3$ principal components. The Oracle--Estimated gap is small
  ($\Delta\text{precision} < 0.05$ at $T/N=5$), confirming generated-regressor
  noise is second-order. The Raw--Oracle gap is large (up to 0.30 in LASSO
  precision at $T/N=5$), confirming factor removal is necessary. The
  anomalous Oracle $<$ Estimated result at $T/N=4$ is a small-sample
  artefact that may reflect PCA-induced shrinkage: with $T < N$,
  PCA truncation discards small estimated factor loadings, inadvertently
  regularizing the factor-neutral residuals and reducing noise. This
  shrinkage effect dissipates as $T/N$ grows; at $T/N \geq 5$ Oracle
  consistently outperforms Estimated.
\end{table}


\paragraph{Robustness checks (Appendix).} We test robustness to nonlinear
dynamics (threshold-VAR), lag misspecification (VAR(2) estimated with lag-1),
and regularization family (Elastic Net $\alpha \in [0.1, 1.0]$). The $T/N$
barrier persists or worsens under all variations. No convex penalization
achieves F1 $> 0.55$ at $T/N \leq 5$ (the appendix).


\subsection{Mechanism Decomposition: GARCH vs.\ Common Factors}
\label{sec:mechanism}

Table~\ref{tab:mechanism} decomposes the OLS-TE precision failure
across four DGPs, isolating the contribution of GARCH dynamics
and common factor structure.

\begin{table}[htbp]
  \centering
  \caption{OLS-TE Precision by DGP: Mechanism Decomposition}
  \label{tab:mechanism}
  \small
  \begin{tabular}{rcccc}
    \toprule
    & \multicolumn{4}{c}{DGP} \\
    \cmidrule(lr){2-5}
    $T/N$ & Gaussian & GARCH only & Factor only & GARCH+Factor \\
    \midrule
    0.6  & 0.105 & 0.122 & 0.087 & 0.117 \\
    1.2  & 0.153 & 0.133 & 0.101 & 0.136 \\
    2.5  & 0.287 & 0.144 & 0.090 & 0.156 \\
    5.0  & 0.340 & 0.141 & 0.099 & 0.140 \\
    10.0 & 0.402 & 0.114 & 0.120 & 0.116 \\
    16.7 & 0.388 & 0.189 & 0.157 & 0.182 \\
    \bottomrule
  \end{tabular}
  \medskip\\
  \small\textit{Note:} ``Factor only'' = common factors with i.i.d.\ Gaussian
  idiosyncratic shocks; ``GARCH only'' = GARCH(1,1) + $t_5$ innovations,
  no common factors. Precision averaged over $N \in \{30,50,100\}$,
  5 trials per cell. No factor-neutral preprocessing is applied in
  simulation; the Factor-only result therefore reflects precision loss
  from factor contamination in raw-return TE --- even at $T/N=16.7$,
  finite-sample factor loading estimation does not resolve this contamination.
\end{table}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.88\textwidth]{figure_mechanism.png}
  \caption{OLS-TE precision vs.\ $T/N$ by DGP.
           Gaussian precision improves steadily above $T/N=5$, reaching
           0.40 at $T/N=16.7$. Factor-only precision is flat at 0.09--0.16
           regardless of $T/N$, identifying common factor structure as the
           primary driver of the precision barrier.}
  \label{fig:mechanism}
\end{figure}

Three findings emerge. First, under Gaussian innovations, OLS precision
improves steadily with $T/N$, reaching 0.39 at $T/N=16.7$. This confirms
that sample size alone is not the binding constraint in the linear--Gaussian
case. Second, Factor only precision is flat at 0.09--0.16 across all $T/N$
ratios, identifying \emph{common factor contamination} as the primary driver
of the precision barrier: when stocks share common factors, OLS TE
systematically conflates factor-driven co-movement with directed
firm-specific information flow, regardless of sample size. Third, GARCH
dynamics alone produce modest deterioration (0.11--0.19) but the precision
does not exhibit the same flat pattern; the combination of GARCH and factors
(our most realistic DGP) mirrors the factor-only pattern closely.

This mechanism analysis has a direct implication: factor adjustment is not
merely a robustness check but a necessary precondition for meaningful TE
network estimation. Studies that estimate TE on raw returns --- including all
seven papers in Table~\ref{tab:literature} --- face an identification problem
that cannot be resolved by increasing $T$ alone.


% 5. Empirical Results
% ============================================================
\section{Empirical Results}
\label{sec:empirical}

\subsection{Robustness: Raw Returns vs.\ Factor-Neutral Baseline}
\label{sec:factorcontam}

Raw TE exhibits pronounced spikes during COVID-19 and the 2022 rate-hiking
cycle; factor-neutral TE is substantially smoother (Figure~A1,
Appendix). The cross-sectional NIO failure holds under both specifications.
All seven papers in Table~\ref{tab:literature} compute TE on raw returns,
facing this additional contamination beyond the $T/N$ problem.

\subsection{LASSO Density Audit}
\label{sec:lasso_density}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.88\textwidth]{figure4_density_comparison.png}
  \caption{Network density: OLS-TE with 75th-percentile threshold
           (mechanically fixed at 25\%) vs.\ factor-neutral LASSO-TE
           (data-driven, mean $< 1\%$). LASSO's honest regularisation
           confirms the OLS network is noise-driven.}
  \label{fig:density}
\end{figure}

LASSO-TE network density averages 0.2\% at $T=60$ ($T/N=0.6$), rising to
1.0\% at $T=120$, confirming near-empty networks across all window sizes.
Only 27--33\% of rolling windows produce any connected nodes.

\subsection{Cross-Sectional NIO Signal}
\label{sec:nio}

\begin{table}[htbp]
  \centering
  \caption{Portfolio Sort: Factor-Neutral OLS-TE NIO
           ($N \approx 100$, $T = 60$)}
  \label{tab:pilot}
  \small
  \begin{tabular}{lcccccc}
    \toprule
    & \multicolumn{2}{c}{Full (2021--2026)}
    & \multicolumn{2}{c}{Sub-period 1 (2021--2023)}
    & \multicolumn{2}{c}{Sub-period 2 (2023--2026)} \\
    \cmidrule(lr){2-3}\cmidrule(lr){4-5}\cmidrule(lr){6-7}
    Quintile & Ann.\ Ret. & $t$
             & Ann.\ Ret. & $t$
             & Ann.\ Ret. & $t$ \\
    \midrule
    Q1 (Low NIO)  & $+8.36\%$  & $0.81$ & $+2.71\%$  & $0.16$  & $+12.60\%$ & $0.99$ \\
    Q2            & $+10.90\%$ & $1.10$ & $+0.65\%$  & $0.04$  & $+18.59\%$ & $1.53$ \\
    Q3            & $+3.72\%$  & $0.36$ & $-14.17\%$ & $-0.78$ & $+17.14\%$ & $1.41$ \\
    Q4            & $+3.93\%$  & $0.37$ & $-8.75\%$  & $-0.47$ & $+13.45\%$ & $1.08$ \\
    Q5 (High NIO) & $+7.30\%$  & $0.66$ & $-12.31\%$ & $-0.62$ & $+22.01\%$ & $1.78$ \\
    \midrule
    \textbf{L/S}
      & $\mathbf{-1.06\%}$ & $\mathbf{-0.13}$
      & $-15.01\%$ & $-1.08$
      & $+9.41\%$  & $+0.97$ \\
    \bottomrule
  \end{tabular}
  \medskip\\
  \small\textit{Note:} Sub-period sign reversal ($-15\%$ to $+9\%$) is a
  classic overfitting signature.
\end{table}


\subsection{Power Analysis: Signal Degradation Under Estimation Noise}
\label{sec:oracle_nio}

The empirical NIO failure (Section~\ref{sec:nio}) could reflect two problems:
(i) estimation noise destroys a real signal, or (ii) the mechanism itself
does not exist. We cannot tell which. But we can ask: \emph{if} a network-return
channel existed, at what $T/N$ ratio would standard TE methods detect it?

We embed a known network premium in the DGP and measure how estimation noise
degrades the signal. This is a power analysis, not a mechanism test.

\paragraph{Design.} Modify the DGP (Equation~\ref{eq:dgp}) to include:
\begin{equation}
  r_{i,t} = \text{(VAR + factors + GARCH)} + \lambda \cdot \text{NIO}_i + \varepsilon_{i,t}
\end{equation}
where $\text{NIO}_i = (\text{out-degree}_i - \text{in-degree}_i)/(N-1)$ is
the true network outflow (constant across time). The premium $\lambda$ is
calibrated to produce realistic annualized long-short spreads (3--60\%).

We then compute three $t$-statistics for the cross-sectional regression
of mean returns on NIO:
\begin{itemize}
  \item \textbf{Oracle}: NIO computed from true $A$ matrix (no estimation error)
  \item \textbf{Estimated (LASSO)}: NIO computed from LASSO-TE adjacency matrix
  \item \textbf{Estimated (OLS)}: NIO computed from OLS-TE adjacency matrix
\end{itemize}

Table~\ref{tab:oracle_nio} reports results across five premium levels and
three $T/N$ ratios (50 trials per cell).

\begin{table}[htbp]
  \centering
  \caption{Power Analysis: NIO Signal Degradation Under Estimation Noise}
  \label{tab:oracle_nio}
  \small
  \begin{tabular}{lccccc}
    \toprule
    $\lambda$ (ann.\ L/S) & Oracle $t$ & $T/N=2$ & $T/N=5$ & $T/N=10$ \\
    \midrule
     3\%  & 1.79  & $-0.24 \pm 2.07$ & $0.43 \pm 1.75$ & $0.44 \pm 1.60$ \\
    10\%  & 5.74  & $0.20 \pm 1.89$  & $0.74 \pm 1.60$ & $0.53 \pm 1.61$ \\
    16\%  & 9.69  & $0.45 \pm 1.68$  & $0.98 \pm 1.47$ & $0.61 \pm 1.61$ \\
    32\%  & 19.58 & $0.69 \pm 1.38$  & $1.31 \pm 1.25$ & $0.82 \pm 1.62$ \\
    64\%  & 39.34 & $0.81 \pm 1.20$  & $1.54 \pm 1.11$ & $1.17 \pm 1.64$ \\
    \bottomrule
  \end{tabular}
  \medskip\\
  \footnotesize
  \textit{Note:} Reported $t$-statistics from cross-sectional regression:
  mean return $\sim$ NIO. Oracle uses true adjacency matrix; estimated
  values use LASSO-TE. Even with 10\% annualized premium (oracle $t=5.74$),
  estimated $t \approx 0.7$ at $T/N=5$. Signal emerges only at extreme
  premium levels ($>30\%$) far beyond realistic equity risk premia.
  Mean $\pm$ std over 50 Monte Carlo trials.
\end{table}

\paragraph{Results.} At a 10\% annualized premium—economically large but
not absurd—the oracle $t$-statistic is 5.74 (highly significant). But
estimated $t$-statistics are 0.20 at $T/N=2$, 0.74 at $T/N=5$, and 0.53
at $T/N=10$. None approach significance. Even at 32\% annualized (oracle
$t=19.58$), the estimated signal barely exceeds 1.3 at $T/N=5$.

This sets a lower bound on required $T/N$ for detectability. If a network
premium existed at realistic magnitudes ($<15\%$ annualized), $T/N > 10$
would be necessary to detect it with standard TE methods. Most existing
studies operate at $T/N < 5$.

\paragraph{Interpretation.} This does not prove network premia exist or do not
exist. It shows that estimation noise alone is sufficient to destroy the signal
at typical financial $T/N$ ratios. The empirical NIO failure
(Section~\ref{sec:nio}) could reflect either problem—or both.


\subsection{The T/N Barrier}
\label{sec:sweep}

\begin{table}[htbp]
  \centering
  \caption{Binary Split $t$-statistics: Connected vs.\ Isolated Stocks}
  \label{tab:sweep_grid}
  \small
  \begin{tabular}{rcccc}
    \toprule
    & \multicolumn{4}{c}{Window $T$} \\
    \cmidrule(lr){2-5}
    $N$ & $T=60$ & $T=120$ & $T=180$ & $T=252$ \\
    \midrule
    30  \small{(T/N: 2.0--8.4)}  & $+0.80$ & $+1.00$ & $+1.29$ & $+1.96$ \\
    50  \small{(T/N: 1.2--5.0)}  & $-1.01$ & $-1.06$ & $-0.55$ & $-0.33$ \\
    70  \small{(T/N: 0.9--3.6)}  & $-1.45$ & $-1.93$ & $+0.92$ & $-0.44$ \\
    90  \small{(T/N: 0.7--2.8)}  & $-1.25$ & $-1.63$ & $-0.18$ & $-0.75$ \\
    100 \small{(T/N: 0.6--2.5)}  & $-1.02$ & $-2.09$ & $+0.35$ & $-0.65$ \\
    \bottomrule
  \end{tabular}
  \medskip\\
  \small\textit{Note:} $t$-statistic from a two-sample test of 5-day
  factor-adjusted returns: connected stocks (NIO $\neq 0$) vs.\ isolated
  stocks (NIO $= 0$). Factor-neutral LASSO-TE networks.
  No cell exceeds $|t| = 2.09$; none is robust across window sizes.
\end{table}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.88\textwidth]{figure6_TN_barrier.png}
  \caption{$t$-statistic of NIO signal as a function of $T/N$.
           No specification produces a $t$-statistic above 2.0 in both
           sub-periods; sign reversal between sub-periods is consistent
           with overfitting.}
  \label{fig:sweep}
\end{figure}

No combination of $N$ and $T$ produces a robust cross-sectional NIO signal.
 Fama--MacBeth cross-sectional regressions of next-week returns on
standardized NIO yield the same conclusion: the time-series average slope
is statistically indistinguishable from zero (Newey--West $t < 1.5$
across all specifications).

\paragraph{LASSO-TE NIO: network sparsity as evidence.}
We complement the OLS-TE portfolio sort with a LASSO-TE based test.
Across formation windows, the LASSO-TE network contains on average
26 connected stocks (NIO $\neq 0$) and 70 isolated stocks (NIO $= 0$)
out of $N = 96$, with mean network density $0.21\%$. A binary split
comparing 5-day factor-adjusted returns of connected versus isolated
stocks yields $t = -0.34$ (full sample), $t = +0.61$ (2021) and
$t = -0.89$ (2022), with no specification exceeding $|t| = 1.0$.
The LASSO-TE NIO signal is thus indistinguishable from zero economically and statistically.
Importantly, the low density itself corroborates our simulation:
LASSO's honest regularization confirms that the OLS network edges
are predominantly noise, collapsing to $< 1\%$ of potential edges
once false positives are penalized.
The largest $t$-statistic observed ($+1.96$ at $N=30$, $T=252$) is not
replicated for any larger universe. At $N=100$ --- the most relevant
specification for S\&P~500 data --- no window exceeds $|t| = 2.09$, and
signs are inconsistent across window sizes. This pattern is exactly what the
simulation predicts: at the $T/N$ ratios accessible with daily financial
data, TE network topology is not reliably estimated, and signals constructed
from it are indistinguishable from noise.


% ============================================================
% 6. Discussion
% ============================================================
\section{Discussion}
\label{sec:discussion}

\subsection{Sample-Size Planning: How Much Data Is Enough?}

Our simulation results allow us to state the estimation requirements
precisely. For OLS-TE under a Gaussian DGP, precision exceeds 30\% only
at $T/N > 5$ and approaches 40\% at $T/N > 10$. Under the more realistic
GARCH+Factor DGP, precision remains below 20\% at \emph{all} $T/N$ ratios
accessible with daily financial data. For LASSO-TE, precision can exceed
80\% at $T/N > 2.5$, but recall collapses below 20\%, meaning the network
topology is too sparse to support node-level claims. Hub recovery rate
under OLS-TE at $T/N=5$ (N=100, T=500) is just 14\% --- only marginally above the
random-selection baseline of 5.4\% under uniform random node selection.

A practical sample-size planning rule emerges: to achieve hub recovery
above 50\% under a realistic financial DGP, simulations suggest $T/N > 20$
is required. For a cross-sectional universe of $N=100$ stocks, this implies
$T > 2{,}000$ daily observations (approximately 8 years of daily data with
a \emph{stable} network structure). No published paper in Table~\ref{tab:literature}
approaches this threshold.

\subsection{Aggregate Connectedness Recovery}
\label{sec:aggregate_recovery}

A central claim in \citet{billio2012} is that \emph{aggregate} network
connectedness tracks systemic risk. We test this: simulate $N=50$, $T=500$
with regime switch at $t=250$ (density 3\% → 12\%). OLS-TE detects the
increase in 100\% of trials (100 Monte Carlo); LASSO-TE in 89\%. Both
underestimate the \emph{level}: OLS reports 5.1--7.3\% vs.\ true 3--12\%;
LASSO compresses to 0.17--0.39\%. Rolling window robustness: OLS-TE density
correlates $r=0.46$ with truth; LASSO $r=0.09$ (near-empty network).

Conclusion: aggregate connectedness \emph{trends} are partially recoverable,
but node-level hub identities are not. Aggregate measures (mean density,
Diebold-Yilmaz index) benefit from error cancellation and may validly detect
stress-period connectivity increases even when individual edges fail.

\subsection{Hub Sector Identification: Billio-Style Test}
\label{sec:hub_billio}

\citet{billio2012} identify banks/insurers as dominant transmitters.
We test whether TE recovers a designated hub sector: assign 5 hub nodes
out-edge density 30\% (hub→rest) vs.\ 5\% background ($N=50$, $T=500$).

\begin{table}[htbp]
  \centering
  \caption{Hub Sector Detection ($N_{\text{hub}}=5$, $N=50$, $T=500$, 100 trials)}
  \label{tab:hub_billio}
  \small
  \begin{tabular}{lcccc}
    \toprule
    & Hub $>$ median & Kendall $\tau$ & Hub NIO $t$ & Pr[$|t|>1.96$] \\
    \midrule
    OLS-TE   & 0.998 & 0.381 & 7.38 & 100\% \\
    LASSO-TE & 0.212 & 0.116 & 0.72 & 6\% \\
    \midrule
    Random baseline & 0.500 & 0.000 & --- & 5\% \\
    \bottomrule
  \end{tabular}
\end{table}

OLS-TE identifies hub nodes above median in 99.8\% of cases ($t=7.4$, 100\%
significant). LASSO-TE: 21.2\% (below random). Trade-off: OLS preserves
aggregate signal for sector-level inference despite low edge precision;
LASSO's near-empty networks suppress sector rankings.

\subsection{Constructive Strategies}

Three approaches improve reliability: (1) Use hourly/5-minute data (increases
$T$ by 10--80×; trade-off: microstructure noise). (2) Aggregate to 10--20
sectors instead of 100 stocks ($N=12$ sectors, $T=500$ → $T/N=41.7$, above
threshold; sacrifice granularity, gain validity). (3) FDR-controlled inference
(stability selection, Benjamini-Hochberg) makes uncertainty
increase $T$ by 10--80x, pushing $T/N$ above the threshold. Trade-off:
microstructure noise contaminates intraday TE estimates.

\paragraph{2. Aggregate cross-sectionally.} Reduce $N$ to 10--20 sectors
instead of hundreds of stocks. At $N=12$ GICS sectors with $T=500$ days,
$T/N=41.7$—well above the reliable range. Sector-level networks sacrifice
granularity but gain statistical validity.

\paragraph{3. Use FDR-controlled inference.} Stability selection or
Benjamini--Hochberg FDR control on edge $p$-values makes uncertainty
explicit. Does not overcome $T/N$ constraints but quantifies them.

% ============================================================
% 7. Conclusion
% ============================================================
\section{Conclusion}
\label{sec:conclusion}

Financial network papers routinely make node-level claims—hub rankings,
centrality scores, early-warning signals—from data where $T/N < 5$.
We show these claims are unreliable.

At $T/N < 5$, OLS-TE recovers under 17\% of true edges. LASSO achieves
higher precision but collapses to near-empty networks on real data.
Hub detection performs close to random. This is not a small-sample quirk:
even at $T/N=16.7$, precision stays below 20\% under realistic dynamics.
Aggregate trends partially survive, but node-level topology does not.

We also run a power test: plant a 10\% annualized network premium in the DGP
and check if estimation recovers it. Oracle $t=5.74$ (significant); estimated
$t \approx 0.7$ at $T/N=5$ (noise). Even with 30\% annualized premia—far
beyond realistic levels—signals barely emerge at $T/N=10$. Estimation noise
alone destroys plausible network-return channels.

For practitioners: node-level inference requires $T/N \approx 8-10$, far above
most existing work. Aggregate connectedness indices may be defensible; specific
hub identities are not. For researchers: the $T/N$ barrier is binding. Either
aggregate to sectors ($N=10-20$) or use intraday data ($T$ ↑), accepting the
microstructure noise trade-off. Standard approaches at standard sample sizes
do not work.

% ============================================================
% Data and Code Availability
% ============================================================

% ============================================================
% Appendix
% ============================================================
\appendix

\section{Nonparametric TE Comparison}
\label{app:nonparametric}

Our framework uses linear VAR, which reduces TE to Granger causality under
Gaussianity. A natural question is whether nonparametric TE estimators
perform better at low $T/N$.

We implemented a KNN-based nonparametric TE estimator (Kozachenko-Leonenko
entropy, $k=3$ nearest neighbors) and compared it to LASSO under the same
GARCH+Factor DGP. Table~\ref{tab:nonparametric_te} and
Figure~\ref{fig:nonparametric_te} show the results.

\begin{table}[htbp]
  \centering
  \caption{Nonparametric vs Linear TE: Precision Comparison (GARCH+Factor DGP)}
  \label{tab:nonparametric_te}
  \small
  \begin{tabular}{lccc}
    \toprule
    & \multicolumn{2}{c}{Precision (mean $\pm$ std)} \\
    \cmidrule(lr){2-3}
    $T/N$ & LASSO & KNN (Nonparametric) \\
    \midrule
    0.6 & 5.9\% $\pm$ 6.9\% & 6.3\% $\pm$ 4.6\% \\
    2.5 & 14.7\% $\pm$ 13.4\% & 6.7\% $\pm$ 5.4\% \\
    5.0 & 31.8\% $\pm$ 19.5\% & 6.1\% $\pm$ 5.5\% \\
    \midrule
    \multicolumn{3}{l}{\textit{Random baseline: 5\% (sparse network, 5\% edge density)}} \\
    \multicolumn{3}{l}{\textit{OLS excluded: undefined at $T/N < 1$}} \\
    \bottomrule
  \end{tabular}
  \medskip\\
  \footnotesize
  \textit{Note:} KNN performs near-random at all $T/N < 5$. LASSO achieves
  6--77\% precision. Nonparametric methods suffer catastrophic dimensionality
  curse; linear methods are the only feasible approach. Mean $\pm$ std, 50 trials.
\end{table}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{figure_nonparametric_te.png}
  \caption{Nonparametric vs Linear TE precision. KNN achieves 6--13\% across
           all $T/N$ ratios (near random). LASSO improves from 6\% at $T/N=0.6$
           to 77\% at $T/N=5.0$. Linear methods, despite theoretical limitations,
           are the only computationally viable option at financial sample sizes.}
  \label{fig:nonparametric_te}
\end{figure}

At $T/N=5$, KNN achieves 6.1\% precision (near-random); LASSO reaches 31.8\%.
At higher $T/N$, the gap widens: LASSO precision is 77\% vs.\ KNN's 13\% at
$(N=50, T=250)$. Nonparametric estimation fails catastrophically under the
curse of dimensionality. Entropy estimation in even moderate dimensions
($d \geq 2$) requires sample sizes far beyond what financial data provide.

\section{Hub Recovery Rate: Detailed Results}
\label{app:hub}

Table~\ref{tab:hub_recovery} reports top-5 hub recovery rate alongside
edge-level precision and random-selection baseline. The random baseline
gives the expected overlap between two randomly drawn sets of 5 nodes
from a universe of $N$ stocks.

\begin{table}[htbp]
  \centering
  \caption{Hub Recovery Rate (top-5, GARCH+Factor DGP)}
  \label{tab:hub_recovery}
  \small
  \begin{tabular}{llrrccc}
    \toprule
    Method & $N$ & $T$ & $T/N$ & Hub Recovery & Precision & Random Baseline \\
    \midrule
    LASSO-TE & 30 & 60 & 2.0 & 0.16 & 0.30 & 0.17 \\
    LASSO-TE & 30 & 250 & 8.3 & 0.32 & 0.59 & 0.17 \\
    LASSO-TE & 50 & 120 & 2.4 & 0.06 & 0.58 & 0.10 \\
    LASSO-TE & 50 & 500 & 10.0 & 0.42 & 0.79 & 0.10 \\
    LASSO-TE & 100 & 60 & 0.6 & 0.04 & 0.40 & 0.05 \\
    LASSO-TE & 100 & 250 & 2.5 & 0.16 & 0.91 & 0.05 \\
    LASSO-TE & 100 & 500 & 5.0 & 0.30 & 0.95 & 0.05 \\
    OLS-TE & 30 & 60 & 2.0 & 0.18 & 0.14 & 0.17 \\
    OLS-TE & 30 & 250 & 8.3 & 0.26 & 0.18 & 0.17 \\
    OLS-TE & 50 & 120 & 2.4 & 0.14 & 0.16 & 0.10 \\
    OLS-TE & 50 & 500 & 10.0 & 0.16 & 0.13 & 0.10 \\
    OLS-TE & 100 & 60 & 0.6 & 0.02 & 0.11 & 0.05 \\
    OLS-TE & 100 & 250 & 2.5 & 0.14 & 0.15 & 0.05 \\
    OLS-TE & 100 & 500 & 5.0 & 0.14 & 0.11 & 0.05 \\
    \bottomrule
  \end{tabular}
  \medskip\\
  \small\textit{Note:} Hub recovery = fraction of true top-5 out-degree nodes
  recovered in predicted network. Random baseline = expected overlap under
  uniform random selection of 5 nodes from $N$. At $N=100$, the random
  baseline is 5.4\%; OLS-TE achieves 14\% at $T/N=5$ --- only 2.6$\times$
  above chance. At $N=50$, random baseline is 10.1\%; OLS-TE achieves
  16\% at $T/N=10$ --- 1.6$\times$ above chance. Hub identification
  is thus only marginally better than random selection at all
  financially relevant $T/N$ ratios.
\end{table}


\subsection{Horizon Robustness}
\label{sec:horizon}

Table~\ref{tab:horizon} reports binary-split $t$-statistics for the NIO
signal across holding periods of 1, 5, and 21 days.

\begin{table}[htbp]
  \centering
  \caption{NIO Signal: Horizon Robustness}
  \label{tab:horizon}
  \small
  \begin{tabular}{rrrr}
    \toprule
    Holding period & $n_{\text{connected}}$ & $n_{\text{isolated}}$ & $t$-stat \\
    \midrule
    1 day  & 5{,}682 & 15{,}267 & $-0.38$ \\
    5 days & 5{,}682 & 15{,}267 & $-0.46$ \\
    21 days& 5{,}682 & 15{,}267 & $+0.97$ \\
    \bottomrule
  \end{tabular}
  \medskip\\
  \small\textit{Note:} No holding period produces $|t|>1.0$.
  The absence of a NIO signal is robust to horizon choice.
\end{table}

\subsection{Hub Ranking Stability: Kendall's $\tau$}
\label{sec:kendall}

Beyond edge-level precision, we evaluate hub \emph{ranking} stability using
Kendall's $\tau$ between true and estimated out-degree sequences. At $T/N=5$,
OLS-TE achieves $\tau = 0.12$ and LASSO-TE $\tau = 0.24$, corresponding to
roughly 56\% and 62\% ranking concordance respectively. At $T/N=10$, LASSO
improves to $\tau = 0.39$, while OLS remains at 0.18. Hub rankings are thus
only marginally better than random at all financially relevant $T/N$ ratios.

\subsection{Sector Aggregation: Empirical Validation}
\label{sec:sector}

Strategy 2 of Section~\ref{sec:discussion} proposes sector-level aggregation
as a path to reliable network estimation. Table~\ref{tab:sector} validates
this empirically using real equity data.

\begin{table}[htbp]
  \centering
  \caption{Sector Aggregation: T/N and LASSO Network Density}
  \label{tab:sector}
  \small
  \begin{tabular}{rrrrrr}
    \toprule
    Window & Stock $T/N$ & Sector $T/N$ & Stock LASSO density & Sector LASSO density \\
    \midrule
    $T=60$  & 1.2 & 6.0  & 1.0\% & 2.1\% \\
    $T=120$ & 2.4 & 12.0 & 0.4\% & 0.7\% \\
    $T=252$ & 5.0 & 25.2 & 0.3\% & 2.5\% \\
    \bottomrule
  \end{tabular}
  \medskip\\
  \small\textit{Note:} Aggregating $N=50$ stocks to $N=10$ sectors raises
  $T/N$ by a factor of 5. LASSO network density increases 2--8$\times$,
  indicating that sector-level networks have sufficient data for meaningful
  topology estimation, while stock-level networks collapse to near-empty
  under LASSO regularization.
\end{table}


\subsection{Alternative Signal Constructions}
\label{sec:altsig}

Table~\ref{tab:altsig} shows that NIO, weighted out-degree (WOD), and
PageRank all fail to identify hubs reliably at $T/N \leq 5$.

\begin{table}[htbp]
  \centering
  \caption{Hub Recovery by Signal Construction (LASSO-TE, GARCH+Factor)}
  \label{tab:altsig}
  \small
  \begin{tabular}{lrrrr}
    \toprule
    Signal & $T/N=2.4$ & $T/N=2.5$ & $T/N=5$ & $T/N=10$ \\
    \midrule
    NIO      & 0.150 & 0.150 & 0.175 & 0.325 \\
    WOD      & 0.138 & 0.138 & 0.200 & 0.325 \\
    PageRank & 0.100 & 0.100 & 0.100 & 0.300 \\
    \bottomrule
  \end{tabular}
  \medskip\\
  \small\textit{Note:} Random baseline: 10\% at $N=50$.
  WOD modestly outperforms NIO in Kendall $\tau$ (0.18 vs.\ 0.08 at $T/N=5$)
  but no signal consistently exceeds 25\% hub recovery.
\end{table}

\section*{Data and Code Availability}

Replication code and simulation toolkit are available at
\url{https://github.com/sora42y/te-network-research-final}. All simulation results are fully reproducible
from the provided scripts.

% ============================================================
% Bibliography
% ============================================================
\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
